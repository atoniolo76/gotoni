# Example configuration file for gotoni
# Copy this to config.yaml and fill in your values

# Lambda Cloud API key (or set LAMBDA_API_KEY environment variable)
api_key: YOUR_API_KEY_HERE

# Instance mappings: instance-id -> ssh-key-name
instances:
    # example-instance-id: ssh-key-name

# SSH key mappings: ssh-key-name -> private-key-file-path
ssh_keys:
    # ssh-key-name: ssh/lambda-key-1762234839.pem

# Tasks/playbooks to run on instances
tasks:
  # Command tasks run synchronously during setup
  - name: "Install dependencies"
    type: "command"
    command: "sudo apt-get update && sudo apt-get install -y python3-pip curl python3-venv"
  
  - name: "Install uv"
    type: "command"
    command: "curl -LsSf https://astral.sh/uv/install.sh | sh"
    depends_on: ["Install dependencies"]
  
  - name: "Setup Python environment"
    type: "command"
    command: "export PATH=\"$HOME/.local/bin:$PATH\" && uv venv --clear && source .venv/bin/activate && uv pip install -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly --index-strategy unsafe-best-match"
    working_dir: "/home/ubuntu"
    depends_on: ["Install uv"]
  
  # Service tasks run as systemd user services with auto-restart and logging
  - name: "Start vLLM server"
    type: "service"
    command: "export PATH=\"$HOME/.local/bin:$PATH\" && cd /home/ubuntu && source .venv/bin/activate && vllm serve deepseek-ai/DeepSeek-OCR --logits_processors vllm.model_executor.models.deepseek_ocr:NGramPerReqLogitsProcessor --no-enable-prefix-caching --mm-processor-cache-gb 0 --port 8000"
    working_dir: "/home/ubuntu"
    # Optional systemd service options:
    # restart: "always" | "on-failure" | "on-success" | "no" (default: "always")
    # restart_sec: seconds to wait before restarting (default: 10)
    # restart: "always"
    # restart_sec: 10

